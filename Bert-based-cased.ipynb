{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-25T14:37:03.452449Z",
     "iopub.status.busy": "2024-04-25T14:37:03.451649Z",
     "iopub.status.idle": "2024-04-25T14:37:45.791311Z",
     "shell.execute_reply": "2024-04-25T14:37:45.789888Z",
     "shell.execute_reply.started": "2024-04-25T14:37:03.452419Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers \n",
    "!pip install -q peft\n",
    "!pip install -q evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-25T14:37:45.794488Z",
     "iopub.status.busy": "2024-04-25T14:37:45.794047Z",
     "iopub.status.idle": "2024-04-25T14:37:47.538284Z",
     "shell.execute_reply": "2024-04-25T14:37:47.537126Z",
     "shell.execute_reply.started": "2024-04-25T14:37:45.794446Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_csv(\"/kaggle/input/ag-news-classification-dataset/train.csv\")\n",
    "df_test= pd.read_csv(\"/kaggle/input/ag-news-classification-dataset/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-25T14:37:47.540182Z",
     "iopub.status.busy": "2024-04-25T14:37:47.539753Z",
     "iopub.status.idle": "2024-04-25T14:37:47.612166Z",
     "shell.execute_reply": "2024-04-25T14:37:47.611056Z",
     "shell.execute_reply.started": "2024-04-25T14:37:47.540146Z"
    }
   },
   "outputs": [],
   "source": [
    "# Splitting into X-train, X_test, y_train, y_test\n",
    "X_train = df_train['Title'] + \" \" + df_train['Description'] \n",
    "Y_train = df_train['Class Index']\n",
    "\n",
    "x_test = df_test['Title'] + \" \" + df_test['Description'] \n",
    "y_test = df_test['Class Index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-25T14:37:47.615218Z",
     "iopub.status.busy": "2024-04-25T14:37:47.614801Z",
     "iopub.status.idle": "2024-04-25T14:37:54.299606Z",
     "shell.execute_reply": "2024-04-25T14:37:54.298746Z",
     "shell.execute_reply.started": "2024-04-25T14:37:47.615174Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a6e4d97ec9445e5994bef68ab23d24d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38e024f24f1b469ebdbc2bb0bec9abb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdf754aba210419fb28de354561719af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b65f9d58999c40508047068bb3103694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples, \n",
    "                     padding=\"max_length\", # Pad shorter examples to the same length\n",
    "                     truncation=True)      # Truncate longer examples to fit the max length\n",
    "'''\n",
    "takes a list of text examples as input. \n",
    "This function will be responsible for processing the text examples using the loaded tokenizer.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-25T14:37:54.301015Z",
     "iopub.status.busy": "2024-04-25T14:37:54.300634Z",
     "iopub.status.idle": "2024-04-25T14:37:54.918476Z",
     "shell.execute_reply": "2024-04-25T14:37:54.917572Z",
     "shell.execute_reply.started": "2024-04-25T14:37:54.300992Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-25T14:37:54.920247Z",
     "iopub.status.busy": "2024-04-25T14:37:54.919756Z",
     "iopub.status.idle": "2024-04-25T14:38:41.508408Z",
     "shell.execute_reply": "2024-04-25T14:38:41.507537Z",
     "shell.execute_reply.started": "2024-04-25T14:37:54.920219Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenized_X_train = X_train.apply(tokenize_function)\n",
    "tokenized_X_test = x_test.apply(tokenize_function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(item['input_ids']) for item in tokenized_X_train[0:]][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-25T14:49:48.316492Z",
     "iopub.status.busy": "2024-04-25T14:49:48.316038Z",
     "iopub.status.idle": "2024-04-25T14:50:17.543769Z",
     "shell.execute_reply": "2024-04-25T14:50:17.542944Z",
     "shell.execute_reply.started": "2024-04-25T14:49:48.316463Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create Dataset objects\n",
    "train_dataset = Dataset.from_dict({\"input_ids\": [item['input_ids'] for item in tokenized_X_train[0:]][:],\n",
    "                                   \"attention_mask\": [item['attention_mask'] for item in tokenized_X_train[0:]][:],\n",
    "                                   \"labels\": Y_train})\n",
    "\n",
    "eval_dataset = Dataset.from_dict({\"input_ids\": [item['input_ids'] for item in tokenized_X_test[0:]][:],\n",
    "                                  \"attention_mask\": [item['attention_mask'] for item in tokenized_X_test[0:]][:],\n",
    "                                  \"labels\": y_test})\n",
    "\"\"\"\n",
    "This function creates two Dataset objects: train_dataset and eval_dataset.\n",
    "\n",
    "Args:\n",
    "    tokenized_X_train (list): A list containing tokenized representations of the training data.\n",
    "        Each element in the list should be a dictionary with keys 'input_ids' and 'attention_mask' \n",
    "        containing the tokenized input IDs and attention masks for a single training example.\n",
    "    Y_train (list): A list containing the ground truth labels for the training data.\n",
    "        The length of this list should match the length of tokenized_X_train.\n",
    "    tokenized_X_test (list): A list containing tokenized representations of the evaluation data.\n",
    "        Each element in the list should be a dictionary with keys 'input_ids' and 'attention_mask' \n",
    "        containing the tokenized input IDs and attention masks for a single evaluation example.\n",
    "    y_test (list): A list containing the ground truth labels for the evaluation data.\n",
    "        The length of this list should match the length of tokenized_X_test.\n",
    "\n",
    "Returns:\n",
    "    tuple: A tuple containing two Dataset objects:\n",
    "        - train_dataset (Dataset): The training dataset containing input IDs, attention masks, and labels.\n",
    "        - eval_dataset (Dataset): The evaluation dataset containing input IDs, attention masks, and labels.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-25T15:04:07.211127Z",
     "iopub.status.busy": "2024-04-25T15:04:07.210338Z",
     "iopub.status.idle": "2024-04-25T15:04:08.311364Z",
     "shell.execute_reply": "2024-04-25T15:04:08.310279Z",
     "shell.execute_reply.started": "2024-04-25T15:04:07.211094Z"
    }
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig, TaskType\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS, r=1, lora_alpha=1, lora_dropout=0.1\n",
    ")\n",
    "\"\"\"\n",
    "This code snippet creates a LoraConfig object for a Sequence Classification (SEQ_CLS) task using the PEFT library.\n",
    "\n",
    "Args:\n",
    "    task_type (TaskType): The type of NLP task the configuration is intended for.\n",
    "        In this case, it is set to TaskType.SEQ_CLS for Sequence Classification.\n",
    "    r (int, optional): The depth (number of layers) of the LORa module. Defaults to 1.\n",
    "    lora_alpha (float, optional): The alpha parameter for the LORa activation function. Defaults to 1.\n",
    "    lora_dropout (float, optional): The dropout rate for the LORa module. Defaults to 0.1.\n",
    "\n",
    "Returns:\n",
    "    LoraConfig: A LoraConfig object containing the specified configuration parameters for the PEFT library.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-25T15:15:48.850783Z",
     "iopub.status.busy": "2024-04-25T15:15:48.849851Z",
     "iopub.status.idle": "2024-04-25T15:15:49.323214Z",
     "shell.execute_reply": "2024-04-25T15:15:49.322234Z",
     "shell.execute_reply.started": "2024-04-25T15:15:48.850743Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load a pre-trained BERT model for sequence classification with 4 output classes\n",
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-cased', \n",
    "    num_labels=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-25T15:15:53.404411Z",
     "iopub.status.busy": "2024-04-25T15:15:53.403929Z",
     "iopub.status.idle": "2024-04-25T15:15:53.470889Z",
     "shell.execute_reply": "2024-04-25T15:15:53.469657Z",
     "shell.execute_reply.started": "2024-04-25T15:15:53.404377Z"
    }
   },
   "outputs": [],
   "source": [
    "from peft import get_peft_model\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-25T15:15:53.751905Z",
     "iopub.status.busy": "2024-04-25T15:15:53.750751Z",
     "iopub.status.idle": "2024-04-25T15:15:54.058158Z",
     "shell.execute_reply": "2024-04-25T15:15:54.056791Z",
     "shell.execute_reply.started": "2024-04-25T15:15:53.751868Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-25T15:15:54.687729Z",
     "iopub.status.busy": "2024-04-25T15:15:54.686777Z",
     "iopub.status.idle": "2024-04-25T15:15:54.695993Z",
     "shell.execute_reply": "2024-04-25T15:15:54.694510Z",
     "shell.execute_reply.started": "2024-04-25T15:15:54.687683Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-25T15:15:55.875694Z",
     "iopub.status.busy": "2024-04-25T15:15:55.874673Z",
     "iopub.status.idle": "2024-04-25T15:15:55.913497Z",
     "shell.execute_reply": "2024-04-25T15:15:55.912328Z",
     "shell.execute_reply.started": "2024-04-25T15:15:55.875657Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\",  # Output directory for checkpoints etc.\n",
    "                                  evaluation_strategy=\"epoch\",# Evaluate model performance after each epoch\n",
    "                                 num_train_epochs=3)          # Train for 3 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-25T15:15:56.701681Z",
     "iopub.status.busy": "2024-04-25T15:15:56.701285Z",
     "iopub.status.idle": "2024-04-25T15:15:57.224659Z",
     "shell.execute_reply": "2024-04-25T15:15:57.222483Z",
     "shell.execute_reply.started": "2024-04-25T15:15:56.701652Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:368\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m args\n\u001b[1;32m    367\u001b[0m \u001b[38;5;66;03m# Seed must be set before instantiating the model when using model\u001b[39;00m\n\u001b[0;32m--> 368\u001b[0m enable_full_determinism(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mseed) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mfull_determinism \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mset_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhp_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeepspeed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer_utils.py:95\u001b[0m, in \u001b[0;36mset_seed\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m     93\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(seed)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n\u001b[0;32m---> 95\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmanual_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mmanual_seed_all(seed)\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m# ^^ safe to call this function even if cuda is not available\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/random.py:40\u001b[0m, in \u001b[0;36mmanual_seed\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcuda\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39m_is_in_bad_fork():\n\u001b[0;32m---> 40\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmanual_seed_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmps\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mmps\u001b[38;5;241m.\u001b[39m_is_in_bad_fork():\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/cuda/random.py:124\u001b[0m, in \u001b[0;36mmanual_seed_all\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m    121\u001b[0m         default_generator \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdefault_generators[i]\n\u001b[1;32m    122\u001b[0m         default_generator\u001b[38;5;241m.\u001b[39mmanual_seed(seed)\n\u001b[0;32m--> 124\u001b[0m \u001b[43m_lazy_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed_all\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py:229\u001b[0m, in \u001b[0;36m_lazy_call\u001b[0;34m(callable, **kwargs)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_lazy_call\u001b[39m(\u001b[38;5;28mcallable\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[0;32m--> 229\u001b[0m         \u001b[38;5;28;43mcallable\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;66;03m# TODO(torch_deploy): this accesses linecache, which attempts to read the\u001b[39;00m\n\u001b[1;32m    232\u001b[0m         \u001b[38;5;66;03m# file system to get traceback info. Patch linecache or do something\u001b[39;00m\n\u001b[1;32m    233\u001b[0m         \u001b[38;5;66;03m# else here if this ends up being important.\u001b[39;00m\n\u001b[1;32m    234\u001b[0m         \u001b[38;5;28;01mglobal\u001b[39;00m _lazy_seed_tracker\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/cuda/random.py:122\u001b[0m, in \u001b[0;36mmanual_seed_all.<locals>.cb\u001b[0;34m()\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(device_count()):\n\u001b[1;32m    121\u001b[0m     default_generator \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdefault_generators[i]\n\u001b[0;32m--> 122\u001b[0m     \u001b[43mdefault_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmanual_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# Create a Trainer object for model training and evaluation\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-25T15:08:49.627483Z",
     "iopub.status.busy": "2024-04-25T15:08:49.626373Z",
     "iopub.status.idle": "2024-04-25T15:08:49.635370Z",
     "shell.execute_reply": "2024-04-25T15:08:49.634248Z",
     "shell.execute_reply.started": "2024-04-25T15:08:49.627444Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set environment variable to enable device-side assertions\n",
    "os.environ[\"TORCH_USE_CUDA_DSA\"] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-25T15:08:52.606183Z",
     "iopub.status.busy": "2024-04-25T15:08:52.605352Z",
     "iopub.status.idle": "2024-04-25T15:08:54.738541Z",
     "shell.execute_reply": "2024-04-25T15:08:54.736994Z",
     "shell.execute_reply.started": "2024-04-25T15:08:52.606150Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1780\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1778\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1780\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1781\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1782\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1783\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1784\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1785\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1790\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_inner_training_loop\u001b[39m(\n\u001b[1;32m   1788\u001b[0m     \u001b[38;5;28mself\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, args\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, resume_from_checkpoint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, trial\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, ignore_keys_for_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m ):\n\u001b[0;32m-> 1790\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfree_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size \u001b[38;5;241m=\u001b[39m batch_size\n\u001b[1;32m   1792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mauto_find_batch_size:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:3028\u001b[0m, in \u001b[0;36mAccelerator.free_memory\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3026\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeepspeed_engine_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3027\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 3028\u001b[0m \u001b[43mrelease_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/utils/memory.py:65\u001b[0m, in \u001b[0;36mrelease_memory\u001b[0;34m(*objects)\u001b[0m\n\u001b[1;32m     63\u001b[0m     torch\u001b[38;5;241m.\u001b[39mmps\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m objects\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/cuda/memory.py:159\u001b[0m, in \u001b[0;36mempty_cache\u001b[0;34m()\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Releases all unoccupied cached memory currently held by the caching\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;124;03mallocator so that those can be used in other GPU application and visible in\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;124;03m`nvidia-smi`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03m    more details about GPU memory management.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[0;32m--> 159\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_emptyCache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "tpu1vmV38",
   "dataSources": [
    {
     "datasetId": 612351,
     "sourceId": 1095715,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4877899,
     "sourceId": 8226531,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30700,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
